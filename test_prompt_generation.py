#!/usr/bin/env python3
"""
AIæµ‹è¯•å¹³å° - Promptç”Ÿæˆæµ‹è¯•è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
1. é…ç½®ç¯å¢ƒå˜é‡:
   export LLM_API_KEY="your_openai_api_key"
   export LLM_PROVIDER="openai"
   export LLM_MODEL="gpt-4"

2. è¿è¡Œæµ‹è¯•:
   python test_prompt_generation.py
"""

import os
import sys
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from prompts.prompt_manager import PromptManager
from prompts.prompt_config import PromptType
from core.llm_client import LLMClient, LLMConfig, LLMProvider


def test_without_api():
    """ä¸è°ƒç”¨APIçš„Promptæµ‹è¯•"""
    print("=" * 60)
    print("æµ‹è¯•1: Promptæ„å»ºæµ‹è¯• (æ— éœ€API)")
    print("=" * 60)

    # æµ‹è¯•éœ€æ±‚
    requirement = """
    ç”¨æˆ·æ³¨å†ŒåŠŸèƒ½:
    1. è¾“å…¥æ‰‹æœºå·ã€å¯†ç ã€ç¡®è®¤å¯†ç 
    2. æ‰‹æœºå·éœ€è¦çŸ­ä¿¡éªŒè¯
    3. å¯†ç é•¿åº¦8-20ä½
    """

    # æ„å»ºæ¶ˆæ¯
    messages = PromptManager.build_messages(
        prompt_type=PromptType.GENERAL_TEST_CASE,
        user_input=requirement,
        variables={"input_description": requirement}
    )

    print(f"æˆåŠŸæ„å»ºæ¶ˆæ¯: {len(messages)} æ¡")
    print(f"- Systemæ¶ˆæ¯é•¿åº¦: {len(messages[0]['content'])} å­—ç¬¦")
    print(f"- Useræ¶ˆæ¯é•¿åº¦: {len(messages[1]['content'])} å­—ç¬¦")

    # éªŒè¯æ‰€æœ‰Promptç±»å‹
    print("\nå¯ç”¨çš„Promptç±»å‹:")
    for pt in PromptType:
        try:
            prompt = PromptManager.PROMPT_MAP.get(pt)
            if prompt:
                print(f"  âœ“ {pt.value}: {len(prompt)} å­—ç¬¦")
            else:
                print(f"  âœ— {pt.value}: æœªæ‰¾åˆ°")
        except Exception as e:
            print(f"  âœ— {pt.value}: é”™è¯¯ - {e}")

    print("\nâœ… Promptæ„å»ºæµ‹è¯•é€šè¿‡!")
    return True


def test_with_api():
    """è°ƒç”¨APIçš„å®Œæ•´æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: LLM APIè°ƒç”¨æµ‹è¯•")
    print("=" * 60)

    # æ£€æŸ¥API Key
    api_key = os.getenv("LLM_API_KEY")
    if not api_key:
        print("âš ï¸  æœªé…ç½® LLM_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯·è¿è¡Œ: export LLM_API_KEY='your_api_key'")
        return False

    print(f"API Provider: {os.getenv('LLM_PROVIDER', 'openai')}")
    print(f"Model: {os.getenv('LLM_MODEL', 'gpt-4')}")

    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    try:
        client = LLMClient()

        # ç®€å•çš„APIæµ‹è¯•
        api_spec = """
        API: GET /api/users/{id}
        æè¿°: è·å–ç”¨æˆ·ä¿¡æ¯
        å‚æ•°: id (path, required) - ç”¨æˆ·ID
        å“åº”: {"code": 0, "data": {"id": 1, "name": "å¼ ä¸‰"}}
        """

        print("\næ­£åœ¨ç”ŸæˆAPIæµ‹è¯•ç”¨ä¾‹...")

        messages = PromptManager.build_messages(
            prompt_type=PromptType.API_TEST_CASE,
            user_input=api_spec,
            variables={"api_specification": api_spec}
        )

        result = client.generate_json(messages, max_tokens=2000)

        print("\nç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹:")
        print(json.dumps(result, ensure_ascii=False, indent=2)[:1000])

        if "test_cases" in result:
            print(f"\nâœ… æˆåŠŸç”Ÿæˆ {len(result.get('test_cases', []))} ä¸ªæµ‹è¯•ç”¨ä¾‹!")

        client.close()
        return True

    except Exception as e:
        print(f"\nâŒ APIè°ƒç”¨å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\nğŸš€ AIæµ‹è¯•å¹³å° - Promptç”Ÿæˆæµ‹è¯•\n")

    # æµ‹è¯•1: æ— éœ€APIçš„æµ‹è¯•
    test_without_api()

    # æµ‹è¯•2: APIè°ƒç”¨æµ‹è¯•
    test_with_api()

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
